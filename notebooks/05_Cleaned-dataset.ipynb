{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Data Genome Project 2.0\n",
    "## Cleaned datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biam! (pic.biam@gmail.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data and numbers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw = \"..//data//meters//raw//\"\n",
    "path_cleaned = \"..//data//meters//cleaned//\"\n",
    "path_anom = \"..//data//meters//screening//anomalies//\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebooks cleaned meters data-set will be created. Outliers in the raw meters dataset were detected using the [Seasonal Hybrid ESD (S-H-ESD)](https://github.com/twitter/AnomalyDetection) developed by Twitter. This was implemented in R language, the process can be found [here](https://github.com/buds-lab/building-data-genome-project-2/blob/master/notebooks/04_Anomaly-detection.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function removes outliers and 24 hours zero readings\n",
    "def removeBadData(df, metername):\n",
    "\n",
    "    # load anomalies df\n",
    "    df_anom = pd.read_csv(path_anom + metername + \"_anoms.csv\")\n",
    "    # Transform timestamp to datetime object type\n",
    "    df_anom[\"timestamp\"] = pd.to_datetime(\n",
    "        df_anom[\"timestamp\"], format=\"%Y-%m-%d %H:%M:%S\"\n",
    "    )\n",
    "    # Remove timezone offset at the end of timestamp\n",
    "    df_anom[\"timestamp\"] = df_anom.timestamp.apply(lambda d: d.replace(tzinfo=None))\n",
    "    # Set index\n",
    "    df_anom = df_anom.set_index(\"timestamp\")\n",
    "\n",
    "    # Remove outliers\n",
    "    outliers = df_anom.copy()\n",
    "    # replace not null values with 9999 (outliers)\n",
    "    outliers[outliers.isna() == False] = 9999\n",
    "    # Update df with outliers data\n",
    "    df.update(outliers)\n",
    "    # Remove outliers\n",
    "    for datapoint in df.columns:\n",
    "        df[datapoint] = df[datapoint][df[datapoint] != 9999]\n",
    "\n",
    "    # Remove zero gaps\n",
    "    # Calculate daily average and aggregate data\n",
    "    df_daily = df.resample(\"D\").mean()\n",
    "    # De-aggreate data asigning daily mean to each hour\n",
    "    df_hourly = df_daily.resample(\"H\").fillna(method=\"ffill\")\n",
    "\n",
    "    ## This dataset ends on 2017-12-31 00:00:00. Our meter dataset ends on 2017-12-31 23:00:00.##\n",
    "    ## This is solved in the following code ##\n",
    "\n",
    "    # Last row of df_hourly to copy values\n",
    "    sample = df_hourly[df_hourly.index == \"2017-12-31 00:00:00\"]\n",
    "    # Dataframe\n",
    "    rng = pd.DataFrame(\n",
    "        index=pd.date_range(\"2017-12-31 01:00:00\", periods=23, freq=\"H\"),\n",
    "        columns=df.columns,\n",
    "    )\n",
    "    appdf = (\n",
    "        sample.append(rng)\n",
    "        .fillna(method=\"ffill\")\n",
    "        .drop(pd.Timestamp(\"2017-12-31 00:00:00\"))\n",
    "    )\n",
    "    # Append\n",
    "    df_hourly = df_hourly.append(appdf)\n",
    "\n",
    "    # Delete zero values during whole day\n",
    "    for datapoint in df_hourly.columns:\n",
    "        df[datapoint] = df[datapoint][df_hourly[datapoint] > 0]\n",
    "\n",
    "    del (df_anom, outliers, df_daily, df_hourly)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export cleaned datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metername = [\"electricity\",\"water\",\"chilledwater\",\"hotwater\",\"gas\", \"steam\",\"solar\",\"irrigation\"]\n",
    "\n",
    "for meter in metername:    \n",
    "    # load data\n",
    "    df = pd.read_csv(path_raw + meter + \".csv\") \n",
    "    # Transform timestamp to datetime object type\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\n",
    "    # Set index\n",
    "    df = df.set_index(\"timestamp\")\n",
    "    \n",
    "    # Remove bad data\n",
    "    df_clean = removeBadData(df, meter)\n",
    "    df_clean.to_csv(path_cleaned + meter + \"_cleaned.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
