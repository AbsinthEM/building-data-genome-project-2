{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Data Genome Project 2.0\n",
    "## Cleaned datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biam! (pic.biam@gmail.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data and numbers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw = \"..\\\\data\\\\meters\\\\raw\\\\\"\n",
    "path_cleaned = \"..\\\\data\\\\meters\\\\cleaned\\\\\"\n",
    "path_anom = \"..\\\\data\\\\meters\\\\screening\\\\anomalies\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebooks cleaned meters data-set will be created. \n",
    "- Outliers will be replace by `NaN`.These were detected using the [Seasonal Hybrid ESD (S-H-ESD)](https://github.com/twitter/AnomalyDetection) developed by Twitter. This was implemented in R language, the process can be found [here](https://github.com/buds-lab/building-data-genome-project-2/blob/master/notebooks/05_Anomaly-detection.ipynb).\n",
    "- Zero-readings in `electricity`meter will be replaced by `NaN`.\n",
    "- Zero-readings longer than 24 continuous hours (in all meters) will be replaced by `NaN`.\n",
    "\n",
    "This data can be removed using `df.dropna()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original code for the `find_zero_gaps` function was written by this [Kaggle user](https://www.kaggle.com/kevincastro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function find all zero gaps in the meter data set\n",
    "def find_zero_gaps(df, metername):\n",
    "    \n",
    "    # Melt dataframe\n",
    "    df = df.melt(id_vars=\"timestamp\",var_name=\"building_id\",value_name=\"meter_reading\")\n",
    "    \n",
    "    # Initiate\n",
    "    status = {}\n",
    "    gaps = []\n",
    "    total_rows = df.timestamp.count()\n",
    "    pos = 0\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        \n",
    "        # Initialize status for this meter\n",
    "        bmid = str(row[\"building_id\"]) + \"_\" + metername\n",
    "        \n",
    "        if bmid not in status:\n",
    "            status[bmid] = {\n",
    "                \"building_id\": row[\"building_id\"],\n",
    "                \"meter\": metername,\n",
    "                \"start\": None,\n",
    "                \"end\": None,\n",
    "                \"count\": 0,\n",
    "                \"last_ts\": None,\n",
    "            }\n",
    "            \n",
    "        meter_status = status[bmid]\n",
    "        is_zero = row[\"meter_reading\"] == 0\n",
    "        \n",
    "        if is_zero:\n",
    "            \n",
    "            if status[bmid][\"start\"] is None:  # first zero detected\n",
    "                status[bmid][\"start\"] = row[\"timestamp\"]\n",
    "                status[bmid][\"count\"] = 0\n",
    "            else:\n",
    "                status[bmid][\"count\"] = status[bmid][\"count\"] + 1\n",
    "                \n",
    "        else:\n",
    "            if status[bmid][\"start\"] is not None:  # End of gap\n",
    "                status[bmid][\"end\"] = row[\"timestamp\"]\n",
    "                gaps.append(\n",
    "                    (\n",
    "                        row[\"building_id\"],\n",
    "                        metername,\n",
    "                        status[bmid][\"start\"],\n",
    "                        status[bmid][\"end\"],\n",
    "                        status[bmid][\"count\"],\n",
    "                    )\n",
    "                )\n",
    "                status[bmid][\"start\"] = None\n",
    "                status[bmid][\"end\"] = None\n",
    "                status[bmid][\"count\"] = 0\n",
    "                \n",
    "        status[bmid][\"last_ts\"] = row[\"timestamp\"]\n",
    "        progress = round((pos / total_rows) * 100, 2)\n",
    "        \n",
    "        if pos % 10000 == 0:\n",
    "            print(f\"\\rProgress: {progress}%\", end=\"\", flush=True)\n",
    "            \n",
    "        pos = pos + 1\n",
    "\n",
    "    print(f\"\\rProgress: {progress}%\", end=\"\", flush=True)\n",
    "    # close trailing gaps\n",
    "\n",
    "    for bmid in status:\n",
    "        s = status[bmid]\n",
    "        if (s[\"start\"] is not None) & (s[\"end\"] is None):  # Trailing gap\n",
    "            gaps.append(\n",
    "                (s[\"building_id\"], s[\"meter\"], s[\"start\"], s[\"last_ts\"], s[\"count\"])\n",
    "            )\n",
    "    df_gaps = pd.DataFrame.from_dict(gaps)\n",
    "    df_gaps.rename(\n",
    "        columns={0: \"building_id\", 1: \"meter\", 2: \"ts_from\", 3: \"ts_to\", 4: \"cnt\"},\n",
    "        inplace=True,\n",
    "    )\n",
    "    return df_gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function replace the zero-reading that belong to a gap longer than the desired limit with NaN\n",
    "def removeZeroGaps(df, df_gaps, limit):\n",
    "    # This is to reorder columns at the end\n",
    "    col_order = df.columns\n",
    "    # Melt meter dataframe\n",
    "    df = df.melt(id_vars=\"timestamp\",var_name=\"building_id\",value_name=\"meter_reading\")\n",
    "    # Select gaps longer than limit set\n",
    "    df_gaps = df_gaps[df_gaps.cnt > limit].reset_index(drop=True)\n",
    "    \n",
    "    # For each row in gaps list\n",
    "    for i in df_gaps.index:\n",
    "        \n",
    "        # loop progress\n",
    "        percentage = round(((i+1) / len(df_gaps)) * 100, 2)\n",
    "        \n",
    "        # For the gap selected, replace them with NaN\n",
    "        df.loc[\n",
    "            (df[\"building_id\"] == df_gaps[\"building_id\"][i])\n",
    "            & (\n",
    "                (df[\"timestamp\"] >= df_gaps[\"ts_from\"][i])\n",
    "                & (df[\"timestamp\"] < df_gaps[\"ts_to\"][i])\n",
    "            ),\n",
    "            \"meter_reading\",\n",
    "        ] = np.nan\n",
    "        \n",
    "        # print progress\n",
    "        print(f\"\\rProgress: {percentage}%\", end=\"\", flush=True)\n",
    "    \n",
    "    # Unmelt replaced meter dataframe\n",
    "    df = df.pivot(index='timestamp', columns=\"building_id\", values=\"meter_reading\").reset_index(level=0)\n",
    "    # Same order as original\n",
    "    df = df[col_order]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function replace all outliers with nan\n",
    "def removeAnoms(df, metername):\n",
    "    # load data\n",
    "    df = pd.read_csv(path_raw + metername + \".csv\") \n",
    "    # Transform timestamp to datetime object type\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # load anomalies df\n",
    "    df_anom = pd.read_csv(path_anom + metername + \"_anoms.csv\")    \n",
    "    # Transform timestamp to datetime object type\n",
    "    df_anom[\"timestamp\"] = pd.to_datetime(df_anom[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\n",
    "    # Remove timezone offset at the end of timestamp\n",
    "    df_anom[\"timestamp\"] = df_anom.timestamp.apply(lambda d: d.replace(tzinfo=None))\n",
    "    \n",
    "    # Outliers\n",
    "    df_anom = df_anom.set_index(\"timestamp\")\n",
    "    outliers = df_anom.copy()\n",
    "    \n",
    "    # replace not null values with 9999 (outliers)\n",
    "    outliers[outliers.isna() == False] = 9999\n",
    "    \n",
    "    # Set index in original dataset to replace\n",
    "    df = df.set_index(\"timestamp\")\n",
    "    \n",
    "    # Update df with outliers data\n",
    "    df.update(outliers)\n",
    "    \n",
    "    # Replace outliers with nan\n",
    "    df.replace(9999, np.nan, inplace=True)\n",
    "    \n",
    "    # Reset index\n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electricity meter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this meter all zero-readings will be replaced by `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "meter = pd.read_csv(path_raw + \"electricity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1312095"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original number of NaN\n",
    "meter.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all zeros with NaN\n",
    "meter.replace(0,np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2471853"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final number of NaN\n",
    "meter.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data\n",
    "meter.to_csv(path_cleaned + \"electricity_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All remaining meters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes long, but can be ran in several kernels at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files in directory\n",
    "files = glob.glob(path_raw + \"*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\data\\\\meters\\\\raw\\\\chilledwater.csv',\n",
       " '..\\\\data\\\\meters\\\\raw\\\\gas.csv',\n",
       " '..\\\\data\\\\meters\\\\raw\\\\hotwater.csv',\n",
       " '..\\\\data\\\\meters\\\\raw\\\\irrigation.csv',\n",
       " '..\\\\data\\\\meters\\\\raw\\\\solar.csv',\n",
       " '..\\\\data\\\\meters\\\\raw\\\\steam.csv',\n",
       " '..\\\\data\\\\meters\\\\raw\\\\water.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files.remove('..\\\\data\\\\meters\\\\raw\\\\electricity.csv')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\data\\\\meters\\\\raw\\\\chilledwater.csv']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current meter: chilledwater\n",
      "Original number of missing values: 676512\n",
      "detecting gaps for chilledwater meter\n",
      "Progress: 100.0%\n",
      "Replacing in chilledwater meter\n",
      "Progress: 100.0%\n",
      "Final number of missing values: 1919556\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in files[0:1]:\n",
    "    # Metername\n",
    "    metername = file.split(\"\\\\\")[4].split(\".\")[0]\n",
    "    print(\"Current meter: \" + metername)\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Original number of NaN\n",
    "    print(f'Original number of missing values: {df.isna().sum().sum()}')\n",
    "    \n",
    "    # Detect gaps\n",
    "    print(\"detecting gaps for \" + metername + \" meter\")\n",
    "    df_gaps = find_zero_gaps(df, metername)\n",
    "    print()\n",
    "    \n",
    "    # Replace gaps longer than 24 hours wit NaN\n",
    "    print(\"Replacing in \" + metername + \" meter\")\n",
    "    df_zeros = removeZeroGaps(df, df_gaps, 24)\n",
    "    print()\n",
    "    \n",
    "     # Final number of NaN\n",
    "    print(f'Final number of missing values: {df_zeros.isna().sum().sum()}')\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    # Export data\n",
    "    del(df)\n",
    "    df_zeros.to_csv(path_cleaned + metername + \"_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files in directory\n",
    "files = glob.glob(path_cleaned + \"*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\data\\\\meters\\\\cleaned\\\\chilledwater_cleaned.csv',\n",
       " '..\\\\data\\\\meters\\\\cleaned\\\\electricity_cleaned.csv',\n",
       " '..\\\\data\\\\meters\\\\cleaned\\\\gas_cleaned.csv',\n",
       " '..\\\\data\\\\meters\\\\cleaned\\\\hotwater_cleaned.csv',\n",
       " '..\\\\data\\\\meters\\\\cleaned\\\\irrigation_cleaned.csv',\n",
       " '..\\\\data\\\\meters\\\\cleaned\\\\solar_cleaned.csv',\n",
       " '..\\\\data\\\\meters\\\\cleaned\\\\steam_cleaned.csv',\n",
       " '..\\\\data\\\\meters\\\\cleaned\\\\water_cleaned.csv']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "meters = [\"chilledwater\",\"electricity\",\"gas\",\"hotwater\",\"irrigation\",\"solar\",\"steam\",\"water\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing meter: chilledwater\n",
      "Processing meter: electricity\n",
      "Processing meter: gas\n",
      "Processing meter: hotwater\n",
      "Processing meter: irrigation\n",
      "Processing meter: solar\n",
      "Processing meter: steam\n",
      "Processing meter: water\n"
     ]
    }
   ],
   "source": [
    "for (file, meter) in zip (files,meters):\n",
    "    print(\"Processing meter: \" + meter)\n",
    "    df = pd.read_csv(file)\n",
    "    df_cleaned = removeAnoms(df,meter)\n",
    "    df_cleaned.to_csv(path_cleaned + meter + \"_cleaned1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
