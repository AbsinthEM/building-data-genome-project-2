{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Data Genome Project 2.0\n",
    "## Cleaned datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biam! (pic.biam@gmail.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data and numbers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw = \"..//data//meters//raw//\"\n",
    "path_cleaned = \"..//data//meters//cleaned//\"\n",
    "path_anom = \"..//data//meters//screening//anomalies//\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebooks cleaned meters data-set will be created. Outliers in the raw meters dataset were detected using the [Seasonal Hybrid ESD (S-H-ESD)](https://github.com/twitter/AnomalyDetection) developed by Twitter. This was implemented in R language, the process can be found [here](https://github.com/buds-lab/building-data-genome-project-2/blob/master/notebooks/02_Anomaly-detection.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter = pd.read_csv(path_raw + \"irrigation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter = meter.melt(id_vars=\"timestamp\", var_name=\"building_id\",value_name=\"meter_reading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter[\"meter\"] = \"irrigation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>meter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>Panther_lodging_Dianna</td>\n",
       "      <td>0.0</td>\n",
       "      <td>irrigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>Panther_lodging_Dianna</td>\n",
       "      <td>0.0</td>\n",
       "      <td>irrigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>Panther_lodging_Dianna</td>\n",
       "      <td>0.0</td>\n",
       "      <td>irrigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>Panther_lodging_Dianna</td>\n",
       "      <td>0.0</td>\n",
       "      <td>irrigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>Panther_lodging_Dianna</td>\n",
       "      <td>0.0</td>\n",
       "      <td>irrigation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp             building_id  meter_reading       meter\n",
       "0  2016-01-01 00:00:00  Panther_lodging_Dianna            0.0  irrigation\n",
       "1  2016-01-01 01:00:00  Panther_lodging_Dianna            0.0  irrigation\n",
       "2  2016-01-01 02:00:00  Panther_lodging_Dianna            0.0  irrigation\n",
       "3  2016-01-01 03:00:00  Panther_lodging_Dianna            0.0  irrigation\n",
       "4  2016-01-01 04:00:00  Panther_lodging_Dianna            0.0  irrigation"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_gaps = find_zero_gaps(meter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaps longer than 24 hs\n",
    "df_gaps = zero_gaps[zero_gaps[\"cnt\"]>=23].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_zero_gaps(df):\n",
    "    status = {}\n",
    "    gaps = []\n",
    "    total_rows = df.timestamp.count()\n",
    "    pos = 0\n",
    "    for i, row in df.iterrows():\n",
    "        # Initialize status for this meter\n",
    "        bmid = str(row[\"building_id\"]) + \"_\" + str(row[\"meter\"])\n",
    "        if bmid not in status:\n",
    "            status[bmid] = {\n",
    "                \"building_id\": row[\"building_id\"],\n",
    "                \"meter\": row[\"meter\"],\n",
    "                \"start\": None,\n",
    "                \"end\": None,\n",
    "                \"count\": 0,\n",
    "                \"last_ts\": None,\n",
    "            }\n",
    "        meter_status = status[bmid]\n",
    "        is_zero = row[\"meter_reading\"] == 0\n",
    "        if is_zero:\n",
    "            if status[bmid][\"start\"] is None:  # first zero detected\n",
    "                status[bmid][\"start\"] = row[\"timestamp\"]\n",
    "                status[bmid][\"count\"] = 0\n",
    "            else:\n",
    "                status[bmid][\"count\"] = status[bmid][\"count\"] + 1\n",
    "        else:\n",
    "            if status[bmid][\"start\"] is not None:  # End of gap\n",
    "                status[bmid][\"end\"] = row[\"timestamp\"]\n",
    "                gaps.append(\n",
    "                    (\n",
    "                        row[\"building_id\"],\n",
    "                        row[\"meter\"],\n",
    "                        status[bmid][\"start\"],\n",
    "                        status[bmid][\"end\"],\n",
    "                        status[bmid][\"count\"],\n",
    "                    )\n",
    "                )\n",
    "                status[bmid][\"start\"] = None\n",
    "                status[bmid][\"end\"] = None\n",
    "                status[bmid][\"count\"] = 0\n",
    "        status[bmid][\"last_ts\"] = row[\"timestamp\"]\n",
    "        progress = round((pos / total_rows) * 100, 2)\n",
    "        if pos % 10000 == 0:\n",
    "            #print(\"[find_gaps] progress: %\" + str(progress))\n",
    "            print(f\"\\rProgress: {progress}%\", end=\"\", flush=True)\n",
    "        pos = pos + 1\n",
    "\n",
    "    #print(\"[find_gaps] progress: %\" + str(progress))\n",
    "    print(f\"\\rProgress: {progress}%\", end=\"\", flush=True)\n",
    "    # close trailing gaps\n",
    "\n",
    "    for bmid in status:\n",
    "        s = status[bmid]\n",
    "        if (s[\"start\"] is not None) & (s[\"end\"] is None):  # Trailing gap\n",
    "            gaps.append(\n",
    "                (s[\"building_id\"], s[\"meter\"], s[\"start\"], s[\"last_ts\"], s[\"count\"])\n",
    "            )\n",
    "    df_gaps = pd.DataFrame.from_dict(gaps)\n",
    "    df_gaps.rename(\n",
    "        columns={0: \"building_id\", 1: \"meter\", 2: \"ts_from\", 3: \"ts_to\", 4: \"cnt\"},\n",
    "        inplace=True,\n",
    "    )\n",
    "    return df_gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeZeroGaps(meter_df, df_gaps):\n",
    "    meter_df[\"zero\"] = 0\n",
    "    #for i in list(range(len(df_gaps) - 1)):\n",
    "    for i in df_gaps.index:\n",
    "        # loop progress\n",
    "        percentage = round(((i+1) / len(df_gaps)) * 100, 2)\n",
    "        # For the gap selected, mark rows with 1\n",
    "        meter_df.loc[\n",
    "            (meter_df[\"building_id\"] == df_gaps[\"building_id\"][i])\n",
    "            & (\n",
    "                (meter_df[\"timestamp\"] >= df_gaps[\"ts_from\"][i])\n",
    "                & (meter_df[\"timestamp\"] < df_gaps[\"ts_to\"][i])\n",
    "            ),\n",
    "            \"zero\",\n",
    "        ] = 1\n",
    "        # print progress\n",
    "        print(f\"\\rProgress: {percentage}%\", end=\"\", flush=True)\n",
    "\n",
    "    return meter_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/45281597/counting-number-of-consecutive-zeros-in-a-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count consecutive zeros in building\n",
    "ts = test # building column\n",
    "#count\n",
    "ts2 = 1-ts\n",
    "tsgroup = ts.cumsum()\n",
    "count0 = ts2.groupby(tsgroup).transform(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"bdg\":ts,\"count0\":count0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = df[(df.bdg == 0) & (df.count0 > 24)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp                       0\n",
       "Panther_lodging_Dianna       2224\n",
       "Panther_lodging_Dean         1072\n",
       "Panther_lodging_Cora         9985\n",
       "Panther_parking_Lorriane     2721\n",
       "Panther_parking_Asia          620\n",
       "Panther_lodging_Kara         6330\n",
       "Panther_lodging_Drew           67\n",
       "Panther_lodging_Ricky          56\n",
       "Panther_parking_Clarence      951\n",
       "Panther_parking_Adela        3587\n",
       "Panther_lodging_Heather       952\n",
       "Panther_office_Daina         1396\n",
       "Panther_lodging_Arlene         56\n",
       "Panther_office_Catherine      342\n",
       "Panther_other_Bethel          863\n",
       "Panther_lodging_Paulette       56\n",
       "Panther_other_Iva            1093\n",
       "Panther_education_Richard     760\n",
       "Panther_parking_Jody          864\n",
       "Panther_office_Woodrow        548\n",
       "Panther_education_Aurora      766\n",
       "Panther_office_Kristen       4915\n",
       "Panther_office_Antonette      200\n",
       "Panther_office_Valarie       3227\n",
       "Panther_lodging_Georgie      3191\n",
       "Panther_lodging_Shelia        900\n",
       "Panther_lodging_Juliet         65\n",
       "Panther_parking_Stanley      2783\n",
       "Panther_lodging_Bonnie       3961\n",
       "Panther_lodging_Aaron        3816\n",
       "Panther_education_Karri      2151\n",
       "Panther_lodging_Jacquelyn    4396\n",
       "Panther_education_Lacey       735\n",
       "Panther_lodging_Marlyn        975\n",
       "Panther_lodging_Janice         58\n",
       "Panther_office_Larry         1122\n",
       "Panther_lodging_Otis         1631\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meter.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function removes outliers and 24 hours zero readings\n",
    "def removeBadData(df, metername):\n",
    "\n",
    "    # load anomalies df\n",
    "    df_anom = pd.read_csv(path_anom + metername + \"_anoms.csv\")\n",
    "    # Transform timestamp to datetime object type\n",
    "    df_anom[\"timestamp\"] = pd.to_datetime(\n",
    "        df_anom[\"timestamp\"], format=\"%Y-%m-%d %H:%M:%S\"\n",
    "    )\n",
    "    # Remove timezone offset at the end of timestamp\n",
    "    df_anom[\"timestamp\"] = df_anom.timestamp.apply(lambda d: d.replace(tzinfo=None))\n",
    "    # Set index\n",
    "    df_anom = df_anom.set_index(\"timestamp\")\n",
    "\n",
    "    # Remove outliers\n",
    "    outliers = df_anom.copy()\n",
    "    # replace not null values with 9999 (outliers)\n",
    "    outliers[outliers.isna() == False] = 9999\n",
    "    # Update df with outliers data\n",
    "    df.update(outliers)\n",
    "    # Remove outliers\n",
    "    for datapoint in df.columns:\n",
    "        df[datapoint] = df[datapoint][df[datapoint] != 9999]\n",
    "\n",
    "    # Remove zero gaps\n",
    "    # Calculate daily average and aggregate data\n",
    "    df_daily = df.resample(\"D\").mean()\n",
    "    # De-aggreate data asigning daily mean to each hour\n",
    "    df_hourly = df_daily.resample(\"H\").fillna(method=\"ffill\")\n",
    "\n",
    "    ## This dataset ends on 2017-12-31 00:00:00. Our meter dataset ends on 2017-12-31 23:00:00.##\n",
    "    ## This is solved in the following code ##\n",
    "\n",
    "    # Last row of df_hourly to copy values\n",
    "    sample = df_hourly[df_hourly.index == \"2017-12-31 00:00:00\"]\n",
    "    # Dataframe\n",
    "    rng = pd.DataFrame(\n",
    "        index=pd.date_range(\"2017-12-31 01:00:00\", periods=23, freq=\"H\"),\n",
    "        columns=df.columns,\n",
    "    )\n",
    "    appdf = (\n",
    "        sample.append(rng)\n",
    "        .fillna(method=\"ffill\")\n",
    "        .drop(pd.Timestamp(\"2017-12-31 00:00:00\"))\n",
    "    )\n",
    "    # Append\n",
    "    df_hourly = df_hourly.append(appdf)\n",
    "\n",
    "    # Delete zero values during whole day\n",
    "    for datapoint in df_hourly.columns:\n",
    "        df[datapoint] = df[datapoint][df_hourly[datapoint] > 0]\n",
    "\n",
    "    del (df_anom, outliers, df_daily, df_hourly)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export cleaned datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metername = [\"electricity\",\"water\",\"chilledwater\",\"hotwater\",\"gas\", \"steam\",\"solar\",\"irrigation\"]\n",
    "\n",
    "for meter in metername:    \n",
    "    # load data\n",
    "    df = pd.read_csv(path_raw + meter + \".csv\") \n",
    "    # Transform timestamp to datetime object type\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\n",
    "    # Set index\n",
    "    df = df.set_index(\"timestamp\")\n",
    "    \n",
    "    # Remove bad data\n",
    "    df_clean = removeBadData(df, meter)\n",
    "    df_clean.to_csv(path_cleaned + meter + \"_cleaned.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
