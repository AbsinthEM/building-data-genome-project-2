{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Data Genome Project 2.0\n",
    "## Predictive models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biam! (pic.biam@gmail.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data and numbers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime\n",
    "from glob import glob\n",
    "import gc\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = (12,8)\n",
    "mpl.rcParams['font.size'] = 12\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "mpl.style.use('ggplot')\n",
    "\n",
    "# Metrics & Models\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Dev (meter reading)</b></p>\n",
    "<ul>\n",
    "<li><code>timestamp</code>: date and time in the format YYYY-MM-DD hh:mm:ss. 2016 and 2017 data.</li>\n",
    "<li><code>building_id</code>: building code-name with the structure <i>UniqueFirstName_SiteID_primaryspaceusage</i>.</li>\n",
    "<li><code>meter_reading</code>: meter reading in kilowatt hour (kWh) .</li>\n",
    "<li><code>meter</code>: meter type, <code>chilledwater</code>, <code>electricity</code>, <code>gas</code>, <code>hotwater</code>, <code>irrigation</code>, <code>steam</code> or <code>water</code>.</li>\n",
    "</ul>\n",
    "    \n",
    "<p><b>Buildings metadata</b></p>\n",
    "<ul>\n",
    "<li><code>building_id</code>: building code-name with the structure <i>UniqueFirstName_SiteID_primaryspaceusage</i>.</li>\n",
    "<li><code>site_id</code>: animal-code-name for the site.</li>\n",
    "<li><code>primaryspaceusage</code>: Primary space usage of all buildings is mapped using the <a href=\"https://www.energystar.gov/buildings/facility-owners-and-managers/existing-buildings/use-portfolio-manager/identify-your-property-type\" rel=\"nofollow\">energystar scheme building description types</a>. </li>\n",
    "<li><code>sqft</code>: building area in square feet (sq ft). </li>\n",
    "<li><code>lat</code>: latitude in degrees.</li>\n",
    "<li><code>lng</code>: longitude in degrees.</li>\n",
    " <li><code>electricity</code>: presence of this kind of meter in the building. <code>Yes</code> if affirmative, <code>NaN</code> if negative.</li>\n",
    "<li><code>hotwater</code>: presence of this kind of meter in the building. <code>Yes</code> if affirmative, <code>NaN</code> if negative.</li>\n",
    "<li><code>chilledwater</code>: presence of this kind of meter in the building. <code>Yes</code> if affirmative, <code>NaN</code> if negative.</li>\n",
    "<li><code>steam</code>: presence of this kind of meter in the building. <code>Yes</code> if affirmative, <code>NaN</code> if negative.</li>\n",
    "<li><code>water</code>: presence of this kind of meter in the building. <code>Yes</code> if affirmative, <code>NaN</code> if negative.</li>\n",
    "<li><code>irrigation</code>: presence of this kind of meter in the building. <code>Yes</code> if affirmative, <code>NaN</code> if negative.</li>\n",
    "<li><code>solar</code>: presence of this kind of meter in the building. <code>Yes</code> if affirmative, <code>NaN</code> if negative.</li>\n",
    "<li><code>gas</code>: presence of this kind of meter in the building. <code>Yes</code> if affirmative, <code>NaN</code> if negative./li>\n",
    "<li><code>yearbuilt</code>: year built in the format YYYY.</li>\n",
    "<li><code>numberoffloors</code>: number of floors.</li>\n",
    "<li><code>date_opened</code>: date opened in the format D/M/YYYY.</li>\n",
    "<li><code>sub_primaryspaceusage</code>: <a href=\"https://www.energystar.gov/buildings/facility-owners-and-managers/existing-buildings/use-portfolio-manager/identify-your-property-type\" rel=\"nofollow\">energystar scheme building description types</a> subcategory.</li>\n",
    "<li><code>energystarscore</code>: <a href=\"https://www.energystar.gov/buildings/facility-owners-and-managers/existing-buildings/use-portfolio-manager/understand-metrics/how-1-100\">Energy Star Score.</a></li>\n",
    "<li><code>eui</code>: <a href=\"https://www.energystar.gov/buildings/facility-owners-and-managers/existing-buildings/use-portfolio-manager/understand-metrics/what-energy\"> Energy use intensity.</a></li>\n",
    "<li><code>heatingtype</code>: type of building's heating system.</li>\n",
    "<li><code>industry</code>: building industry.</li>\n",
    "<li><code>leed_level</code>: <a href\"https://en.wikipedia.org/wiki/Leadership_in_Energy_and_Environmental_Design\">Leadership in Energy and Environmental Design.</a></li>\n",
    "<li><code>occupants</code>: number of ccupants?</li>\n",
    "<li><code>rating</code>: building rating (system or criteria?)</li>\n",
    "<li><code>site_eui</code>: site energy use intensity.</li>\n",
    "<li><code>source_eui</code>: ?</li>\n",
    "<li><code>sqm</code>: buildinga area in square meters?</li>\n",
    "<li><code>subindustry</code>: building subindustry.</li>\n",
    "<li><code>timezone</code>: time zone.</li>\n",
    "</ul>\n",
    "    \n",
    "<p><b>Weather</b></p>\n",
    "<ul>\n",
    "<li><code>timestamp</code>: date and time in the format YYYY-MM-DD hh:mm:ss.</li>\n",
    "<li><code>site_id</code>: animal-code-name for the site.</li>\n",
    "<li><code>apparentTemperature</code>: The apparent (or “feels like”) temperature in degrees Fahrenheit (ºF).</li>\n",
    "<li><code>cloudCover</code>: The percentage of sky occluded by clouds, between <code>0</code> and <code>1</code>, inclusive.</li>\n",
    "<li><code>dewPoint</code>: The dew point in degrees Fahrenheit (ºF).</li>\n",
    "<li><code>humidity</code>: The relative humidity, between <code>0</code> and <code>1</code>, inclusive.</li>\n",
    "<li><code>precipIntensity</code>: The intensity (in inches of liquid water per hour) of precipitation occurring at the given time (in/h)</li>\n",
    "<li><code>precipType</code>:The type of precipitation occurring at the given time. If defined, this property will have one of the following values: <code>\"rain\"</code>, <code>\"snow\"</code>, or <code>\"sleet\"</code> (which refers to each of freezing rain, ice pellets, and “wintery mix”). (If <code>precipIntensity</code> is zero, then this property will not be defined.</li>\n",
    "<li><code>pressure</code>: The sea-level air pressure in millibars (mbar or hPa).</li>\n",
    "<li><code>summary</code>:A human-readable text summary of this data point.</li>\n",
    "<li><code>temperature</code>:The air temperature in degrees Fahrenheit (ºF).</li>\n",
    "<li><code>uvIndex</code>: The UV index, between <code>0</code> and <code>11</code>, inclusive.</li>\n",
    "<li><code>visibility</code>: The average visibility in miles, capped at 10 miles (mi).</li>\n",
    "<li><code>windBearing</code>: The direction that the wind is coming <em>from</em> in degrees, with true north at 0° and progressing clockwise (degrees).</li>\n",
    "<li><code>windGust</code>: The wind gust speed in miles per hour (mi/h).</li>\n",
    "<li><code>windSpeed</code>: The wind speed in miles per hour (mi/h).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook only a selection of features will be used.<br>\n",
    "\n",
    "<i>Building metadata</i>\n",
    "<ul>\n",
    "    <li>Building ID*</li>\n",
    "    <li>Site ID*</li>\n",
    "    <li>Primary space usage</li>\n",
    "    <li>Building size (sqft)</li>\n",
    "</ul>\n",
    "<i>Weather data</i>\n",
    "<ul>\n",
    "    <li>Timestamp*</li>\n",
    "    <li>Site ID*</li>\n",
    "    <li><a href=https://en.wikipedia.org/wiki/Apparent_temperature>Apparent temperature</a></li>\n",
    "</ul>\n",
    "<i>Meter reading data</i>\n",
    "<ul>\n",
    "    <li>Timestamp*</li>\n",
    "    <li>Building ID*</li>\n",
    "    <li>meter</li>\n",
    "    <li>meter reading (target)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_metadata = \"..\\\\data\\\\metadata\\\\\"\n",
    "path_weather = \"..\\\\data\\\\weather\\\\\"\n",
    "path_meter = \"..\\\\data\\\\meters\\\\processed\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53561832 entries, 0 to 53561831\n",
      "Data columns (total 4 columns):\n",
      "timestamp        object\n",
      "building_id      object\n",
      "meter_reading    float64\n",
      "meter            object\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 1.6+ GB\n"
     ]
    }
   ],
   "source": [
    "# Meter reading data\n",
    "data = pd.read_csv(path_meter + \"allmeters.csv\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1636 entries, 0 to 1635\n",
      "Data columns (total 4 columns):\n",
      "building_id          1636 non-null object\n",
      "site_id              1636 non-null object\n",
      "primaryspaceusage    1615 non-null object\n",
      "sqft                 1636 non-null float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 51.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Buildings metadata\n",
    "metadata = pd.read_csv(path_metadata + \"metadata.csv\", usecols = [\"building_id\",\n",
    "                                                                 \"site_id\",\n",
    "                                                                 \"primaryspaceusage\",\n",
    "                                                                 \"sqft\",\n",
    "                                                                 ])\n",
    "metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 333288 entries, 0 to 333287\n",
      "Data columns (total 3 columns):\n",
      "timestamp              333288 non-null object\n",
      "site_id                333288 non-null object\n",
      "apparentTemperature    333288 non-null float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Weather data\n",
    "weather = pd.read_csv(path_weather + \"weather.csv\", usecols = [\"timestamp\",\n",
    "                                                                  \"site_id\",\n",
    "                                                                  \"apparentTemperature\"\n",
    "                                                                  ])\n",
    "weather.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing memory size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to reduce the DF size\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1430.26 Mb (12.5% reduction)\n",
      "Mem. usage decreased to  0.04 Mb (12.5% reduction)\n",
      "Mem. usage decreased to  5.72 Mb (25.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "# Reduce memory\n",
    "data = reduce_mem_usage(data)\n",
    "metadata = reduce_mem_usage(metadata)\n",
    "weather = reduce_mem_usage(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering based on EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <ul>\n",
    "    <li><i>Healthcare</i> and <i>Utility</i> usages shows the highest meter reading values.</li>\n",
    "    <li><i>Steam</i> meter shows the highest meter reading values.</li>\n",
    "    <li>Monthly behaviour (meter-reading median):\n",
    "    <ul>\n",
    "        <li><i>Utility</i> usage peaks in April-March.</li>\n",
    "        <li><i>Chilledwater</i> meter shows higher values in warm season.</li>\n",
    "        <li><i>Steam</i> meter shows lower values in April-October.</li>\n",
    "    </ul>\n",
    "    </li>\n",
    "    <li>Hourly behaviour (meter-reading median):\n",
    "    <ul>\n",
    "        <li>Higher values from 6 hs to 19 hs.</li>\n",
    "        <li><i>Utility</i> usage shows oposite tendency.</li>\n",
    "        <li><i>Steam</i> meter pikes from 5 hs to 8 hs.</li>\n",
    "    </ul>\n",
    "    </li>\n",
    "        <li>Weekday behaviour: lowers during weekends.</li>\n",
    "</ul>\n",
    "</li>     \n",
    " Based on this observations <i>month</i>, <i>day of the week</i> and <i>hour of the day</i> will be added. <code>primaryspaceusage</code> categories (16) will be reduced to <i>healthcare, utility</i> and <i>other</i>. <code>meter</code> categories (8) will be preserved. Final features will be:\n",
    " <ul>\n",
    "    <li>Timestamp*</li>\n",
    "    <li>Building ID*</li>\n",
    "    <li>Month</li>\n",
    "    <li>Hour</li>\n",
    "    <li>Day of the week</li>\n",
    "    <li>Usage (dummy, 3 levels: <i>healthcare, utility, other</i>)</li>\n",
    "    <li>Building size (sqft)</li>\n",
    "    <li>Apparent temperature</li>\n",
    "    <li>Meter (dummy, 8 levels)</li>\n",
    "    <li>Meter reading / target</li>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce primary space usage categories to 3: Healthcare, Utilty, other\n",
    "metadata.loc[(metadata[\"primaryspaceusage\"] != \"Healthcare\") & (metadata[\"primaryspaceusage\"] != \"Utility\"), \"primaryspaceusage\"] = \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['other', 'Healthcare', 'Utility'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check new categories\n",
    "metadata.primaryspaceusage.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts to timestamp\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\n",
    "weather[\"timestamp\"] = pd.to_datetime(weather[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add features\n",
    "data[\"month\"] = data.timestamp.dt.month\n",
    "data[\"weekday\"] = data.timestamp.dt.weekday\n",
    "data[\"hour\"] = data.timestamp.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets\n",
    "data = data.merge(metadata, how=\"left\", on=\"building_id\").merge(weather, how=\"left\", on = [\"timestamp\", \"site_id\"])\n",
    "del(weather, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop site_id (is no longer needed for now, is in building_id)\n",
    "data = data.drop(\"site_id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missings?\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(path_meter + \"dev_merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color=\"red\">**To do:** list models to apply.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 55\n",
    "\n",
    "models = {\n",
    "    'Dummy'            : DummyRegressor(),\n",
    "    'Linear'           : LinearRegression(),\n",
    "    'ElasticNet'       : ElasticNet(alpha=.1, random_state=seed),\n",
    "    'DecisionTree'     : DecisionTreeRegressor(random_state=seed),\n",
    "    'RandomForest'     : RandomForestRegressor(random_state=seed, n_jobs=-1, n_estimators=10),\n",
    "    'Bagging'          : BaggingRegressor(random_state=seed, n_jobs=-1, n_estimators = 10, max_features = 1.0, max_samples = 0.25),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function applies all models and save each set-model prediction in seaparate csv files\n",
    "# Input: train data, train target, val data, val target, satrategy name, savepath\n",
    "# Output: a csv file for each model and each dataset (train and val) saved in savepath\n",
    "\n",
    "def AllModelsPrediction(X_train, y_train, X_val, name, savepath):\n",
    "    print(\"Start time: \" + str(datetime.datetime.now()))\n",
    "    print(\"\")\n",
    "    \n",
    "    for model in models: # for each model in dictionary\n",
    "        print(\"Current model: \" + str(model))\n",
    "        t0 = datetime.datetime.now() # start time\n",
    "        \n",
    "        # Fit model\n",
    "        trained_model = models[model].fit(X_train, y_train.values.ravel()) # train model with train dataset\n",
    "        print(str(model) +\" model training complete\")\n",
    "        \n",
    "        # Predict train and val\n",
    "        val_pred = trained_model.predict(X_val) # predict val dataset\n",
    "        del(trained_model)\n",
    "        print(str(model) + \" model prediction complete\")\n",
    "        \n",
    "        # Save files\n",
    "        pd.DataFrame(val_pred, columns=[str(model)]).to_csv(savepath + name + \"_\" + str(model) + \".csv\", index=False)\n",
    "        del(val_pred)\n",
    "        print(str(model) + \" model predictions saved\")\n",
    "        \n",
    "        print(str(model) + \" model total time needed: \" + str(datetime.datetime.now() - t0))\n",
    "        print(\"\")\n",
    "        gc.collect()\n",
    "    \n",
    "    print(\"Finish time: \" + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function concatenate all prediction in one dataframe\n",
    "# input: files directory list\n",
    "# output: single dataframe with all predictions\n",
    "\n",
    "def ConcatAllModels(files):\n",
    "    dfs = [] # empty list of the dataframes to create\n",
    "    for file in files: # for each file in directory\n",
    "        #model_name = file.split(\"\\\\\")[2].split(\"_\")[1].split(\".\")[0] # model_name to rename the model feature\n",
    "        model = pd.read_csv(file) # load the dataset\n",
    "        dfs.append(model) # append to list\n",
    "    complete_data = pd.concat(dfs, axis=1, ignore_index=False, sort=False) # concatenate all models\n",
    "   \n",
    "    return complete_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long term prediction: whole year 2017 prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train:** whole year 2016 (01/2016 to 12/2016)<br>\n",
    "**Validation:** whole year 2017 (01/2017 to 12/2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(path_meter + \"dev_merged.csv\")\n",
    "# Reduce memory\n",
    "data = reduce_mem_usage(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts to timestamp\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy split\n",
    "train = data[data[\"timestamp\"] < \"2017-01-01 00:00:00\"]\n",
    "val = data[data[\"timestamp\"] >= \"2017-01-01 00:00:00\"]\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.set_index([\"timestamp\",\"building_id\"])\n",
    "val = val.set_index([\"timestamp\",\"building_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_real = val[[\"timestamp\",\"building_id\",\"meter\",\"meter_reading\"]]\n",
    "val_real.to_csv(\"..\\\\predictions\\\\longterm_real.csv\", index=False)\n",
    "del(val_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding and Data/Target split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For linear models and decision tree based models (SciKit) use OneHotEncoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Dummies\n",
    "train = pd.get_dummies(train, columns = [\"meter\",\"primaryspaceusage\"], drop_first=True)\n",
    "val = pd.get_dummies(val, columns = [\"meter\",\"primaryspaceusage\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For LightGBM use only a label encoding (this algorith can handle categorical features by itself):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoder\n",
    "le_meter = LabelEncoder().fit(train.meter)\n",
    "train[\"meter\"] = le_meter.transform(train.meter)\n",
    "val[\"meter\"] = le_meter.transform(val.meter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoder\n",
    "le_usage = LabelEncoder().fit(train.primaryspaceusage)\n",
    "train[\"primaryspaceusage\"] = le_usage.transform(train.primaryspaceusage)\n",
    "val[\"primaryspaceusage\"] = le_usage.transform(val.primaryspaceusage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split datasets\n",
    "X_train = train.drop(\"meter_reading\", axis=1)\n",
    "y_train = train[\"meter_reading\"]\n",
    "\n",
    "X_val = val.drop(\"meter_reading\", axis=1)\n",
    "y_val = val[\"meter_reading\"]\n",
    "\n",
    "del(train, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default parameters: https://lightgbm.readthedocs.io/en/latest/Parameters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    categorical_feature=[\"meter\",\"primaryspaceusage\"],\n",
    "    free_raw_data=False,\n",
    ")\n",
    "lgb_eval = lgb.Dataset(\n",
    "    X_val,\n",
    "    y_val,\n",
    "    categorical_feature=[\"meter\",\"primaryspaceusage\"],\n",
    "    reference=lgb_train,\n",
    "    free_raw_data=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (Default)\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"random_state\": 55\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "print('Starting training...')\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                valid_sets = lgb_eval,\n",
    "                num_boost_round=10000,\n",
    "                early_stopping_rounds=7500,\n",
    "                verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "print('Starting predicting...')\n",
    "y_pred = gbm.predict(X_val, num_iteration=gbm.best_iteration)\n",
    "print('Finish.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, counts = np.unique(y_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(values)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save LightGBM prediction\n",
    "pd.DataFrame(y_pred).to_csv(\"..\\\\predictions\\\\longterm_LGBM.csv\", index=False, header=\"LGBM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciKit-Learn models prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SciKit models\n",
    "name = \"s1\"\n",
    "savepath = \"..\\\\predictions\\\\\"\n",
    "AllModelsPrediction(X_train, y_train, X_val, name, savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To export a single dataset with all the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(X_train, X_val, y_train, y_val)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath\n",
    "files = glob(\"..\\\\predictions\\\\longterm*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenates all predictions\n",
    "df_pred = ConcatAllModels(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_pred[[\"timestamp\",\"building_id\",\"meter\",\"meter_reading\",\"LGBM\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves files\n",
    "df_pred.to_csv(\"..\\\\predictions\\\\longterm_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short term prediction: weekly prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train:**<br>\n",
    "**validation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(path_meter + \".csv\")\n",
    "# Reduce memory\n",
    "data = reduce_mem_usage(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts to timestamp\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy split\n",
    "train = data[data[\"timestamp\"] < ]\n",
    "val = data[(data[\"timestamp\"] >= ) & (data[\"timestamp\"] < )]\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_real = val[[\"timestamp\",\"building_id\",\"meter\",\"meter_reading\"]]\n",
    "val_real.to_csv(\"..\\\\predictions\\\\shortterm_real.csv\", index=False)\n",
    "del(val_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding and Data/Target split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.set_index([\"timestamp\",\"building_id\"])\n",
    "val = val.set_index([\"timestamp\",\"building_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For linear models and decision tree based models (SciKit) use OneHotEncoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Dummies\n",
    "train = pd.get_dummies(train, columns = [\"meter\",\"primaryspaceusage\"], drop_first=True)\n",
    "val = pd.get_dummies(val, columns = [\"meter\",\"primaryspaceusage\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For LightGBM use only a label encoding (this algorithm can handle categorical features by itself):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoder\n",
    "le_meter = LabelEncoder().fit(train.meter)\n",
    "train[\"meter\"] = le_meter.transform(train.meter)\n",
    "val[\"meter\"] = le_meter.transform(val.meter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoder\n",
    "le_usage = LabelEncoder().fit(train.primaryspaceusage)\n",
    "train[\"primaryspaceusage\"] = le_usage.transform(train.primaryspaceusage)\n",
    "val[\"primaryspaceusage\"] = le_usage.transform(val.primaryspaceusage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split datasets\n",
    "X_train = train.drop(\"meter_reading\", axis=1)\n",
    "y_train = train[\"meter_reading\"]\n",
    "\n",
    "X_val = val.drop(\"meter_reading\", axis=1)\n",
    "y_val = val[\"meter_reading\"]\n",
    "\n",
    "del(train, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default parameters: https://lightgbm.readthedocs.io/en/latest/Parameters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    categorical_feature=[\"meter\",\"primaryspaceusage\"],\n",
    "    free_raw_data=False,\n",
    ")\n",
    "lgb_eval = lgb.Dataset(\n",
    "    X_val,\n",
    "    y_val,\n",
    "    categorical_feature=[\"meter\",\"primaryspaceusage\"],\n",
    "    reference=lgb_train,\n",
    "    free_raw_data=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (Default)\n",
    "params = {\"objective\": \"regression\",\n",
    "          \"metric\":\"rmse\",\n",
    "          \"random_state\": 55}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "print('Starting training...')\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                valid_sets = lgb_eval,\n",
    "                early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "print('Starting predicting...')\n",
    "y_pred = gbm.predict(X_val, num_iteration=gbm.best_iteration)\n",
    "print('Finish.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save LightGBM prediction\n",
    "pd.DataFrame(y_pred, columns=['LGBM']).to_csv(\"..\\\\predictions\\\\shortterm_LGBM.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciKit-Learn models prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SciKit models\n",
    "name = \"s2a\"\n",
    "savepath = \"..\\\\predictions\\\\\"\n",
    "AllModelsPrediction(X_train, y_train, X_val, name, savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To export a single dataset with all the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(X_train, X_val, y_train, y_val, y_pred)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath\n",
    "files = glob(\"..\\\\predictions\\\\shortterm*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenates all predictions\n",
    "df_pred = ConcatAllModels(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_pred[[\"timestamp\",\"building_id\",\"meter\",\"meter_reading\",\"LGBM\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves files\n",
    "df_pred.to_csv(\"\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
